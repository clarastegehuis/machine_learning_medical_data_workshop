{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voor je begint met de code runnen**\n",
    "\n",
    "Klik op <kbd>Runtime</kbd>  bovenaan de pagine, en op <kbd>runtime options</kbd>. Selecteer daar een vakje waar <kbd>GPU</kbd>  bij staat.\n",
    "\n",
    "**Hoe gebruik je dit bestand?**\n",
    "\n",
    "Dit bestand is een *jupyter notebook*, dat bestaat uit tekstcellen (zoals deze) en codecellen (zoals die hierboven). Code cellen kun je runnen met <kbd>shift</kbd> + <kbd>enter</kbd>. Voordat je verder gaat, is het belangrijk om de cel hierboven te runnen, zodat de computer alle nodige functies kan importeren.\n",
    "In sommige gevallen moet je zelf een stukje code schrijven. Geen paniek, er lopen hier genoeg mensen rond om je een handje te helpen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%pip install medmnist\n",
    "from medmnist import PneumoniaMNIST\n",
    "\n",
    "%pip install SimpleITK\n",
    "import SimpleITK as sitk\n",
    "\n",
    "    \n",
    "!git clone https://github.com/clarastegehuis/machine_learning_medical_data_workshop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De wiskunde achter AI - *Toepassing: medische data*\n",
    "Neurale netwerken kunnen worden gebruikt om automatisch beelden te interpreteren. Computers zijn zelfs beter in sommige beeldanalyse taken dan mensen, omdat mensen een korte concentratieboog hebben. \n",
    "In deze workshop krijg je een inkijkje in hoe een computer beelden kan interpreteren. We gaan aan de slag met een (openbare) medische dataset en ons eigen netwerk trainen wat onderscheid kan maken tussen plaatjes van zieke en gezonde longen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Digitale beelden\n",
    "Een computer ziet een beeld als een grote matrix met getallen, elk element in de matrix (beter bekend als *pixel*) bevat de lokale beeldintensiteit. In het geval van een kleurenbeeld zijn het drie matrices over elkaar, die respectievelijk het rode, blauwe en groene kanaal voorstellen. In het geval van een zwart-wit beeld is het digitale beeld een enkele matrix met intensiteiten.\n",
    "\n",
    "Hieronder laden we eerst een beeld uit de zogenaamde Ribs dataset, die röntgenfoto's van ribbenkasten bevat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definieert twee functies die je later kan gebruiken om de images te openen en te visualiseren\n",
    "def open_img(path):\n",
    "    if path.endswith('.png'):\n",
    "        return np.array(Image.open(path).convert('L'))\n",
    "    elif path.endswith('.mhd'):\n",
    "        return sitk.GetArrayFromImage(sitk.ReadImage(path))[32,:,:] # return 1 slice of the image\n",
    "\n",
    "def visualize(img, clim=[-300,450]):\n",
    "    plt.imshow(img, cmap='gray', clim=clim)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inladen van beeld van de ribbenkast\n",
    "# definieer pad naar beeld\n",
    "# img_path = 'data/ribs/VinDr_RibCXR_train_000.png'\n",
    "img_path = '/content/machine_learning_medical_data_workshop/TEV1P1CTI.mhd'\n",
    "img = open_img(img_path)\n",
    "# visualiseer beeld\n",
    "visualize(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uit hoeveel pixels bestaat dit beeld? np.shape(img) laat de vorm (aantal rijen en kolommen) van de matrix zien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(img))\n",
    "\n",
    "# Hoe veel pixels zijn dit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convoluties\n",
    "Een computer kan een beeld begrijpen door middel van zogenaamde convoluties. Een convolutie bestaat altijd uit een *kernel*, een kleine matrix met daarin een kenmerkend patroon, die lokaal wordt vermenigvuldigd met de beeldintensiteiten. In de onderstaande animatie is het bovenste groene vlak de kernel, en het blauwe vlak het te interpreteren beeld, het schuiven van de kernel noemen we de convolutie. Het resultaat van een convolutie is nog steeds een *matrix*, die vergelijkbare afmetingen heeft als het originele beeld.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/0/04/Convolution_arithmetic_-_Padding_strides.gif?20190413174630)\n",
    "\n",
    " Met een convolutie wordt in feite de intensiteit van iedere pixel vergeleken met die van zijn buren, afhankelijk van het patroon in de kernel. Door het patroon in de kernel slim te kiezen, kunnen bepaalde features in het beeld worden opgepikt, bijvoorbeeld verticale randen. Effectief wordt er per pixel gekeken hoe zijn omgeving matcht met het patroon in de kernel. Daarnaast kan een convolutie gebruikt worden om ruis in een beeld te verminderen, dit noemen we *smoothing*.\n",
    " \n",
    " Hieronder laten we een paar voorbeelden van convolutiekernels zien, aan jullie om te beschrijven wat voor effect ze hebben op het beeld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dit is een functie die een convolution toepast op een beeld\n",
    "def apply_conv(image, kernel, iter=1):\n",
    "    image, kernel = torch.from_numpy(image).float(), torch.from_numpy(kernel).float()\n",
    "    img_shape, kernel_shape = image.shape, kernel.shape\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    for level in range(iter):\n",
    "        image = F.conv2d(image.reshape(1,1, img_shape[0], img_shape[1]),\n",
    "                         kernel.reshape(1,1, kernel_shape[0], kernel_shape[1]),\n",
    "                         padding='same').squeeze()\n",
    "        ax.imshow(image.numpy(), cmap='gray', clim=[-300,450])\n",
    "        ax.set_title(f'Applied convolution {level+1} times')\n",
    "        display(fig)\n",
    "        clear_output(wait=True)\n",
    "        plt.pause(0.1)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kun je zelf een kernel loslaten op het beeld van de ribben. \n",
    "\n",
    "**Vraag:**\n",
    "Wat gebeurt er met het beeld door de convolutie? En wat gebeurt er als je meerdere convoluties achter elkaar toepast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutie 1: detecteren verschuiven naar links\n",
    "# eerst kernel definieren:\n",
    "kernel = np.array([[0, 0, 0],\n",
    "                   [0, 0, 1],\n",
    "                   [0, 0, 0]])\n",
    "# hoe vaak willen we de convolutie toepassen?\n",
    "n_iters = 20\n",
    "\n",
    "apply_conv(img, kernel, n_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De tweede convolutie veschuift het beeld naar boven. \n",
    "\n",
    "**Vraag:** Kun je ook een convolutie maken die het beeld naar rechts beneden schuift (schuin)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutie 2: verschuiven naar boven\n",
    "# eerst kernel definieren:\n",
    "kernel = np.array([[0, 0, 0],\n",
    "                   [0, 0, 0],\n",
    "                   [0, 1, 0]])\n",
    "# hoe vaak willen we de convolutie toepassen?\n",
    "n_iters = 20\n",
    "\n",
    "apply_conv(img, kernel, n_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als het goed is heb je hierboven begrepen hoe je een beeld naar rechts, links, boven of onder kan verplaatsen, of schuin kan verplaatsen. Als je de kernel groter maakt, kun je je beeld ook ingewikkeldere sprongen laten maken. \n",
    "\n",
    "**Vraag:**\n",
    "Kun je bijvoorbeeld met een $5 \\times 5$ kernel het beeld een paardensprong laten maken? (2 pixels omhoog, en 1 naar links)? Nu staan er alleen maar nullen in de kernel, dus je moet 1 of meerdere vakjes aanpassen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht: maak een convolutie die het beeld een paardensprong laat maken: i\n",
    "kernel = np.array([[0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0]])\n",
    "\n",
    "n_iters = 20\n",
    "\n",
    "apply_conv(img, kernel, n_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De convolutie hieronder past 'smoothing' toe, en maakt het beeld onscherper. \n",
    "\n",
    "**Vraag:** Wat gebeurt er als je de gewichten in de kernel iets aanpast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutie 3: Een convolutie die 'smoothing' toepast: Voor iedere pixel neemt de convolution het gewogen gemiddelde van de pixelwaarde en de pixelwaarden van de 8 omliggende pixels. Wat gebeurt er als je de gewichten van de kernel aanpast?\n",
    "kernel = np.array([[1, 2, 1],\n",
    "                   [2, 4, 2],\n",
    "                   [1, 2, 1]]) * 1/16\n",
    "\n",
    "n_iters = 20\n",
    "\n",
    "apply_conv(img, kernel, n_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De onderstaande convolutie hadden we eerder al gezien, die vindt verticale lijnen. Deze convolutie hoef je maar één keer toe te passen, omdat je in een keer alle lijnen kunt vinden. \n",
    "\n",
    "**Vraag:** Kun je ook een convolutie maken die horizontale lijnen vindt? En wat gebeurt er als je de 1 en en -1 en omdraait?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutie 3: detecteren van verticale lijnen\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                   [1, 0, -1],\n",
    "                   [1, 0, -1]])\n",
    "\n",
    "n_iters = 1\n",
    "\n",
    "apply_conv(img, kernel, n_iters)\n",
    "\n",
    "\n",
    "# opdracht:kun je ook een kernel maken die horizontale randen vindt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "Deze convolutieoperaties vormen de basis van een zogenaamd *convolutional neural network*. In principe is dit een neuraal netwerk dat kan worden ingezet voor allerlei computer vision taken, zoals het classificeren van beelden, objecten detecteren of zelfs de precieze grenzen van een object vinden in een beeld. Convolutional neural networks bestaan uit een stapeling van convoluties. Door convoluties vaker toe te passen in een 'stapel', kan de computer een groeiende lokale regio rondom elke pixel kan bekijken (perceptive field).\n",
    "De kernels in al deze convoluties worden niet door mensen bepaald, maar worden bepaald tijdens het *trainen* van dit netwerk. In de rest van dit notebook laten we een klein voorbeeld zien van hoe dit werkt en hoe we kunnen bepalen hoe goed dit netwerk is in zijn taak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**De taak:**\n",
    "\n",
    "We maken gebruik van de zogenaamde pneumonia dataset. Deze bevat gedownsamplede röntgenfoto's van de borstkas, van zowel gezonde patienten als van patienten met een longontsteking. We gaan een neuraal netwerk trainen dat automatisch voor een dergelijk beeld kan bepalen of er sprake is van longontsteking of niet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downoald de dataset met foto's van de longen\n",
    "import medmnist\n",
    "%pip install monai\n",
    "\n",
    "dataset = medmnist.PneumoniaMNIST(split=\"train\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "# maakt een custom dataset class die de data in de juiste vorm geeft\n",
    "\n",
    "class MedMNISTData(monai.data.Dataset):\n",
    "    \n",
    "    def __init__(self, datafile, transform=None):\n",
    "        self.data = datafile\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Make getitem return a dictionary with keys ['img', 'label'] for the image and label respectively\n",
    "        image = torch.from_numpy(np.array(self.data[index][0])).float()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return {'img': image, 'label': self.data[index][1]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Een functie die de foto's uit de dataset visualiseert\n",
    "def visualize_sample(sample):\n",
    "    plt.imshow(sample['img'], 'gray')\n",
    "    if sample['label'] == 1:\n",
    "        plt.title('Patient with pneumonia')\n",
    "    else:\n",
    "        plt.title('Healthy patient')\n",
    "    plt.xticks([]) \n",
    "    plt.yticks([]) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensiteiten normaliseren voor het netwerk straks en de training data maken\n",
    "from monai.transforms import NormalizeIntensity\n",
    "\n",
    "data_transform = NormalizeIntensity(subtrahend=.5, divisor=.5)\n",
    "\n",
    "train_dataset = MedMNISTData(dataset, transform=data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vraag 1 (doel: experimenteren met code en dataset verkennen): \n",
    "train_dataset is een verzameling van 4708 scans waarin elke scan een label heeft, deze kan 0 of 1 zijn. Label 0 betekent dat de patient gezond is, en label 1 betekent dat de patient longontsteking heeft , Als je <kbd>visualize(train_dataset[k][‘img’])</kbd> intoetst dan kun je het $k$-de plaatje zien, en als je <kbd>print(train_dataset[k][‘label’])</kbd> intoetst dan zie je de label die bij dat plaatje hoort. Experimenteer met <kbd>visualize_sample(train_dataset[k])</kbd> om de dataset te verkennen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder kun je een foto de longen van een willekeurige patient laten zien. Om de voorspellingen van het algoritme later beter te kunnen interpreteren, is het belangrijk om te weten hoe veel foto's er in de data zitten van gezonde longen, en hoe veel er van ongezonde longen inzitten.\n",
    "\n",
    "Hieronder kun je kijken hoe veel data uit de ene, en uit de andere klasse komen.\n",
    "\n",
    "**Vraag:** Is de dataset gebelanceerd? Hoe veel procent van de trainingsdata gaat over patienten met een longontsteking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiseer een random sample\n",
    "index = np.random.choice(np.arange(len(train_dataset)))\n",
    "visualize_sample(train_dataset[index])\n",
    "\n",
    "#Vraag: is deze dataset imbalanced? \n",
    "counts = {0: 0, 1:0}\n",
    "for sample in train_dataset:\n",
    "    counts[sample['label'][0]] += 1\n",
    "print('Aanal label 0:', counts[0], 'Aantal label 1:', counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu gaan we het echte netwerk aanmaken. We splitsen de data in een testset en een validatieset om later te kunnen kijken of het model niet overfit. We maken een model met twee lagen van convoluties van 3x3 kernels. Daarachter komt een neuraal netwerk, en we zorgen dat er één output is (wel of niet longontsteking). Dit model staat geprogrammeerd als Net().\n",
    "\n",
    "\n",
    "**Vraag:** \n",
    "Wat is de receptive field van dit netwerk (hoe veel pixels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validatiedataset aanmaken, om te kijken hoe het model generaliseert tijdens het trainen. De validatieset wordt niet gebruikt om de gewichten van het model op te fitten.\n",
    "val_dataset = MedMNISTData(medmnist.PneumoniaMNIST(split='val', download=False))\n",
    "\n",
    "# dataloader die de data inlaadt voor het trainen\n",
    "train_dataloader = monai.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = monai.data.DataLoader(val_dataset, batch_size = 32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier wordt het echte model gedefinieerd. Dit model is een convolutioneel neuraal netwerk (CNN) dat bestaat uit 2 convolutionele lagen en 2 fully connected lagen.\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)             # Een convolutie met 1 input channel (de afbeelding), 32 output channels (32 verschillende kernels), 3x3 pixel kernel\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)            # Een tweede convolutie met 32 input channels (de 32 output channels van de vorige laag), 64 output channels (verschillende kernels), 3x3 pixel kernel\n",
    "        self.fc1 = nn.Linear(in_features=9216, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=1)                                       # De output laag met 1 output neuron (de voorspelling, tussen 0 (geen longontsteking) en 1( longontsteking) )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        output = self.fc2(x)\n",
    "        return output\n",
    "    \n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We moeten ook bepalen wat de loss functie is die het netwerk gebruikt als we gaan trainen. We gebruiken de 'binary cross-entropy loss' die we besproken hadden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.cuda() # op de GPU zetten, zodat het trainen sneller gaat\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "# loss functie: Binary cross entropy (want classificatie). \n",
    "loss_function = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# functie om het model te trainen\n",
    "\n",
    "def train_medmnist(model, train_dataloader, val_dataloader, optimizer, epochs, device='cuda', val_freq=1):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # model in train modus\n",
    "        model.train()\n",
    "        steps = 0\n",
    "        epoch_loss = 0\n",
    "        # loop over de batches in training data\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            images = batch['img'].float().to(device)\n",
    "            labels = batch['label'].float().to(device)\n",
    "            # haal plaatjes door het model\n",
    "            output = model(images.unsqueeze(1)) \n",
    "            # bereken de loss tussen de targets en de outputs van het model\n",
    "            loss = loss_function(output, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            # back propagation, update de weights in het netwerk\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            steps += 1\n",
    "           \n",
    "        train_loss.append(epoch_loss/steps)\n",
    "\n",
    "        # validation loop\n",
    "        if epoch % val_freq == 0:\n",
    "            steps = 0\n",
    "            val_epoch_loss = 0\n",
    "            model.eval()\n",
    "            for batch in val_dataloader:\n",
    "                images = batch['img'].float().to(device)\n",
    "                labels = batch['label'].float().to(device)\n",
    "                output = model(images.unsqueeze(1)) \n",
    "                loss = loss_function(output, labels)\n",
    "                val_epoch_loss += loss.item()\n",
    "                steps += 1\n",
    "            val_loss.append(val_epoch_loss/steps)\n",
    "\n",
    "    # plot the losses together\n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.plot(np.arange(0, epochs, val_freq), val_loss, label='val loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we het neurale netwerk, de loss functie, de data geïntroduceerd is, kunnen we het model echt gaan trainen, en de kernels leren die het model gaat gebruiken om gezonde en ongezonde patiënten te onderscheiden. De code hieronder laat zien hoe de loss functie naar beneden gaat tijdens de training, op zowel te trainingsdata als de validatiedata. \n",
    "\n",
    "\n",
    "**Vraag:** Als je de plots van de loss functie op de trainingsdata en op de validatiedata ziet, is het model dan overfitted denk je? En nu hebben we het model 100 epochs getraind. Had dit ook korter gekund?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_freq = 10\n",
    "\n",
    "# 100 iteraties trainen\n",
    "n_epochs = 100\n",
    "model, train_loss, val_loss = train_medmnist(model, train_dataloader, val_dataloader, optimizer, epochs=n_epochs, val_freq=val_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben hierboven gezien wat specifieke kernels kunnen herkennen in een beeld. Maar wat heeft ons algoritme voor kernels gevonden om te classificeren tussen gezonde en zieke longen? Hieronder zien we de kernels van de tweede laag van convoluties. Omdat de eerste laag al 16 convoluties heeft gedaan, zijn er 16 verschillende lagen van kernels in de tweede laag. Je kunt ze allemaal bekijken door de variabele <kbd>input_index</kbd> aan te passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = 16\n",
    "fig, axs = plt.subplots(8,8, layout='constrained')\n",
    "for i in range(64):\n",
    "    kernel = model.conv2.weight[i,input_index,:,:].detach().cpu().numpy()\n",
    "    cur_ax = np.unravel_index(i, [8,8])\n",
    "    s = axs[cur_ax].imshow(kernel, clim=[-0.1,0.1],cmap = 'Greys')\n",
    "    axs[cur_ax].axis('off')\n",
    "plt.suptitle(f'Geleerde kernels uit de tweede convolutional laag, input channel {input_index}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En hier zien we ook de kernels uit de eerste laag van convoluties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(model.conv1.weight))\n",
    "fig, axs = plt.subplots(4,8, layout='constrained')\n",
    "for i in range(32):\n",
    "    kernel = model.conv1.weight[i,0,:,:].detach().cpu().numpy()\n",
    "    cur_ax = np.unravel_index(i, [4,8])\n",
    "    s = axs[cur_ax].imshow(kernel, clim=[-0.1,0.1],cmap = 'Greys')\n",
    "    axs[cur_ax].axis('off')\n",
    "plt.suptitle(f'Geleerde kernels uit de eerste convolutional laag')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance assessment\n",
    "\n",
    "Nu we het model getraind hebben, gaan we kijken in hoeverre dit model goede voorspellingen kan doen. Eerst bepalen we de recall en precision van het model. De recall vertelt ons hoeveel van de positieven er gemist worden door het model (vals negatieven). De precisie meet hoeveel van de positief geclassificeerde samples daadwerkelijk positieve samples zijn (vals positieven). Welke maat belangrijker is, is afhankelijk van het probleem. Bij het detecteren van een extreem zeldzame vorm van kanker heb je bijvoorbeeld het liefst een hoge recall en accepteer je daarmee een lagere precisie. Het is beter om de daadwerkelijke positieven wél te detecteren en daarmee in een vervolgonderzoek de vals positieven eruit te filteren, dan de positieven compleet te missen.\n",
    "We gebruiken de test dataset (dus niet de validatiedataset) om deze metrics te bepalen.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png)\n",
    "\n",
    "Voordat we deze metrics gaan bepalen, bekijken we eerst een paar outputs van het model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_results_visualize(model, dataset):\n",
    "    index = np.random.randint(0, len(dataset))\n",
    "    image = dataset[index]['img']\n",
    "    plt.imshow(image.numpy().squeeze(), cmap='gray')\n",
    "    image = image.float().to('cuda')\n",
    "    label = dataset[index]['label'].item()\n",
    "    with torch.no_grad():\n",
    "        output = F.sigmoid(model(image.view(1,1,28,28))).squeeze()\n",
    "    plt.yticks([]) \n",
    "    plt.xticks([]) \n",
    "    plt.title(f'Echte waarde: {label}, voorspelling model: {int(output)}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    validation_results_visualize(model, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deze functien berekent de precision en recall van het model\n",
    "def get_precision_recall(model, dataloader):\n",
    "    model.eval()\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    total = 0\n",
    "    for data in dataloader:\n",
    "        images = data['img'].float().to('cuda')\n",
    "        labels = data['label'].squeeze()\n",
    "        total += len(labels)\n",
    "        with torch.no_grad():\n",
    "            output = F.sigmoid(model(images.unsqueeze(1))).squeeze().cpu()\n",
    "        pred_classes = (output >= 0.5).to(torch.int8)\n",
    "        TP += (pred_classes * labels).sum()\n",
    "        TN += ((1 - pred_classes) * (1 - labels)).sum()\n",
    "        FP += (pred_classes * (1 - labels)).sum()\n",
    "        FN += ((1 - pred_classes) * labels).sum()\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    return precision, recall   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MedMNISTData(medmnist.PneumoniaMNIST(split='test', download=False))\n",
    "test_loader = monai.data.DataLoader(test_dataset, batch_size = 32, shuffle=False)\n",
    "\n",
    "precision, recall = get_precision_recall(model, test_loader)\n",
    "print(f'De precision van het getrainde model is {precision:.2f}, de recall van het getrainde model is {recall:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vraag:** Wat vind je van de precisie en recall van het model (ook denkend aan hoe veel procent van de patienten in de data longontsteking hebben?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder kun je een zogenaamde 'confusion matrix' zien. Hoe veel longontstekingen zijn over het hoofd gezien? En hoe vaak wordt er een patient onterecht gediagnostiseerd met longontsteking? Welk beeld geeft dit van hoe krachtig het model is? Kun je er ook achterkomen of het model ook goed werkt op de validatiedataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(model,dataloader):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using true and predicted labels.\n",
    "\n",
    "    :param y_true: List or array of true labels.\n",
    "    :param y_pred: List or array of predicted labels.\n",
    "    :param labels: List of label names (optional).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "   \n",
    "    for data in dataloader:\n",
    "        images = data['img'].float().to('cuda')\n",
    "        labels = data['label'].squeeze()\n",
    "        with torch.no_grad():\n",
    "            output = F.sigmoid(model(images.unsqueeze(1))).squeeze().cpu()\n",
    "        pred_classes = (output >= 0.5).to(torch.int8)\n",
    "        true_labels.extend(labels.numpy())\n",
    "        predicted_labels.extend(pred_classes.numpy())\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['geen longontsteking', 'longontsteking'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
